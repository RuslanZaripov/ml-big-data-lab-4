{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "bv9pfNvjx5jG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import pathlib\n",
        "import pandas as pd\n",
        "\n",
        "import json\n",
        "from google.colab import userdata\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
        "from torchvision import transforms\n",
        "import copy\n",
        "from PIL import Image\n",
        "import torch.nn as nn\n",
        "from tqdm.auto import tqdm\n",
        "import multiprocessing\n",
        "\n",
        "from sklearn import metrics\n",
        "import seaborn as sns\n",
        "\n",
        "import time\n",
        "import math\n",
        "\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "3wjlczrhx19d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download dataset"
      ],
      "metadata": {
        "id": "QdKBkhV4STWC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lq2wR1WtSLuv"
      },
      "outputs": [],
      "source": [
        "!pip install -q kaggle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir ~/.kaggle\n",
        "!touch ~/.kaggle/kaggle.json\n",
        "\n",
        "api_token = {\"username\": userdata.get('username'),\n",
        "             \"key\": userdata.get('key')}\n",
        "\n",
        "with open('/root/.kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(api_token, file)\n",
        "\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "SW3iuPoLSksr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c dogs-vs-cats"
      ],
      "metadata": {
        "id": "PBr6jvTSSRnA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/dogs-vs-cats.zip"
      ],
      "metadata": {
        "id": "kN-sf1K_SSjC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q -o test1.zip"
      ],
      "metadata": {
        "id": "M-X8D3YoTCeg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q -o train.zip"
      ],
      "metadata": {
        "id": "7fpmqAgkT9Vb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list(filter(lambda x: '.csv' in x, list(os.listdir('test1'))))"
      ],
      "metadata": {
        "id": "pkwxSxWwTIba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(list(os.listdir('test1')))"
      ],
      "metadata": {
        "id": "GiKMZxIST_lF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(list(os.listdir('train')))"
      ],
      "metadata": {
        "id": "Zt9gS29RUCP0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_submission = pd.read_csv('sampleSubmission.csv')"
      ],
      "metadata": {
        "id": "ZqVRaaW2ToQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_submission['label'].value_counts()"
      ],
      "metadata": {
        "id": "HL_qeLLgT5-9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare dataset"
      ],
      "metadata": {
        "id": "2Sro6u2fT7ng"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_dataset(dataset_root, test_ratio=0.2):\n",
        "    out_train_fname = 'train.csv'\n",
        "    out_test_fname = 'val.csv'\n",
        "\n",
        "    print(\"Running splitting dataset to Train and Test\")\n",
        "    print(f\"test_ratio: {test_ratio}\")\n",
        "    print(f\"dataset_root: {dataset_root}\")\n",
        "    print(f\"out_train_fname: {out_train_fname}\")\n",
        "    print(f\"out_test_fname: {out_test_fname}\")\n",
        "\n",
        "    image_counter = {}\n",
        "\n",
        "    out_train_files = []\n",
        "    out_test_files = []\n",
        "\n",
        "    cur_dir = pathlib.Path(dataset_root)\n",
        "\n",
        "    if not cur_dir.is_dir():\n",
        "        return\n",
        "\n",
        "    img_names = list(map(str, [item for item in cur_dir.rglob(\"*\")\n",
        "                               if item.is_file()\n",
        "                               and str(item).lower().endswith(('.jpg', '.jpeg', '.png'))]))\n",
        "\n",
        "    img_names = list(map(lambda it: it.split('/')[-1], img_names))\n",
        "\n",
        "    def create_csv(class_name):\n",
        "        instance_files = [tf for tf in img_names if class_name in tf]\n",
        "\n",
        "        image_counter[class_name] = len(instance_files)\n",
        "\n",
        "        test_size = int(len(instance_files) * test_ratio)\n",
        "        test_files = random.sample(instance_files, test_size)\n",
        "\n",
        "        for img_name in img_names:\n",
        "\n",
        "            p = f'{class_name},{img_name}\\n'\n",
        "\n",
        "            if img_name in test_files:\n",
        "                out_test_files.append(p)\n",
        "            else:\n",
        "                out_train_files.append(p)\n",
        "\n",
        "    create_csv('dog')\n",
        "    create_csv('cat')\n",
        "\n",
        "    with open(f'{dataset_root}/{out_train_fname}', 'w') as f:\n",
        "        f.write('label,img_name\\n')\n",
        "        f.writelines(out_train_files)\n",
        "    print(f'Number of train images: {len(out_train_files)}')\n",
        "\n",
        "    with open(f'{dataset_root}/{out_test_fname}', 'w') as f:\n",
        "        f.write('label,img_name\\n')\n",
        "        f.writelines(out_test_files)\n",
        "    print(f'Number of test images: {len(out_test_files)}')\n",
        "\n",
        "    return len(image_counter), image_counter"
      ],
      "metadata": {
        "id": "qU1Bneu2T9oS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_root = '/content/train'\n",
        "num_classes, image_counter = split_dataset(dataset_root, 0.1)\n",
        "print(f\"{num_classes=}\\n{image_counter=}\\n{len(image_counter)=}\")"
      ],
      "metadata": {
        "id": "jOjtPpYJUNmz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_test(dataset_root):\n",
        "    out_test_fname = 'test.csv'\n",
        "\n",
        "    cur_dir = pathlib.Path(dataset_root)\n",
        "\n",
        "    if not cur_dir.is_dir():\n",
        "        return\n",
        "\n",
        "    img_names = list(map(str, [item for item in cur_dir.rglob(\"*\")\n",
        "                               if item.is_file()\n",
        "                               and str(item).lower().endswith(('.jpg', '.jpeg', '.png'))]))\n",
        "\n",
        "    img_names = list(map(lambda it: it.split('/')[-1] + '\\n', img_names))\n",
        "\n",
        "    with open(f'{dataset_root}/{out_test_fname}', 'w') as f:\n",
        "        f.write('label\\n')\n",
        "        f.writelines(img_names)\n",
        "\n",
        "    print(f'Number of test images: {len(img_names)}')"
      ],
      "metadata": {
        "id": "JV3uTKn1gCmM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "create_test('test1')"
      ],
      "metadata": {
        "id": "HOZKbNuigob0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_val = pd.read_csv('train/val.csv')\n",
        "df_val.head()"
      ],
      "metadata": {
        "id": "wXWpzu_WyLFT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = pd.read_csv('test1/test.csv')\n",
        "df_test.head()"
      ],
      "metadata": {
        "id": "l9U3MSySgyZf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Variables"
      ],
      "metadata": {
        "id": "zAUmb9RW8rJE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "num_workers = multiprocessing.cpu_count()\n",
        "seed = 2025\n",
        "lr = 1e-4\n",
        "batch_size = 32"
      ],
      "metadata": {
        "id": "Vdk-ryo4SMin"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ],
      "metadata": {
        "id": "uaD2NFwFyhm5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, dataset_root, csv_filename, transform):\n",
        "        print(\"Reading Image Dataset...\")\n",
        "        self.dataset_root = dataset_root\n",
        "\n",
        "        print(\"Reading dataset file paths...\")\n",
        "        self.csv_filename = csv_filename\n",
        "        self.img_labels = pd.read_csv(f'{dataset_root}/{self.csv_filename}', delimiter=',')\n",
        "        self.transform = transform\n",
        "        print(\"Image Dataset instance created!\")\n",
        "\n",
        "        if 'test' not in self.csv_filename:\n",
        "            self.classes = self.img_labels['label'].unique().tolist()\n",
        "            self.label_to_idx = {val: idx for idx, val in enumerate(self.classes)}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_labels)\n",
        "\n",
        "    def get_labels(self):\n",
        "        if 'test' not in self.csv_filename:\n",
        "            return list(map(self.label_to_idx.get, self.img_labels.iloc[:, 0]))\n",
        "        else:\n",
        "            return []\n",
        "\n",
        "    def read_image(self, img_name):\n",
        "        img_path = f'{self.dataset_root}/{img_name}'\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        image_tensor = self.transform(image)\n",
        "        image.close()\n",
        "        return image_tensor\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        if 'test' not in self.csv_filename:\n",
        "            label = self.img_labels.iloc[index, 0]\n",
        "            img_name = self.img_labels.iloc[index, 1]\n",
        "            return self.read_image(img_name), self.label_to_idx[label]\n",
        "        else:\n",
        "            img_name = self.img_labels.iloc[index, 0]\n",
        "            return self.read_image(img_name), img_name"
      ],
      "metadata": {
        "id": "ofKz2uxOXaZq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.ColorJitter(),\n",
        "    transforms.RandomCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.Resize(128),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.ToTensor()\n",
        "])"
      ],
      "metadata": {
        "id": "NxPJym9myqcF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_datasets = dict()\n",
        "image_datasets['train'] = ImageDataset(dataset_root=dataset_root,\n",
        "                                       csv_filename='train.csv',\n",
        "                                       transform=train_transform)\n",
        "\n",
        "image_datasets['val'] = ImageDataset(dataset_root=dataset_root,\n",
        "                                      csv_filename='val.csv',\n",
        "                                      transform=test_transform)"
      ],
      "metadata": {
        "id": "uyPxwjzg82mQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def seed_worker(worker_id):\n",
        "    worker_seed = torch.initial_seed() % 2**32\n",
        "    np.random.seed(worker_seed)\n",
        "    random.seed(worker_seed)\n",
        "\n",
        "g = torch.Generator()\n",
        "g.manual_seed(seed)\n",
        "\n",
        "dataloaders = dict()\n",
        "dataloaders['train'] = DataLoader(image_datasets['train'],\n",
        "                                  batch_size=batch_size,\n",
        "                                  shuffle=True,\n",
        "                                  num_workers=num_workers,\n",
        "                                  pin_memory=True,\n",
        "                                  drop_last=True,\n",
        "                                  worker_init_fn=seed_worker,\n",
        "                                  generator=g)\n",
        "dataloaders['val'] = DataLoader(image_datasets['val'],\n",
        "                                 batch_size=batch_size,\n",
        "                                 shuffle=False,\n",
        "                                 num_workers=num_workers,\n",
        "                                 pin_memory=True,\n",
        "                                 worker_init_fn=seed_worker,\n",
        "                                 generator=g)"
      ],
      "metadata": {
        "id": "ZCPEuLJgbeLV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "samples, labels = next(iter(dataloaders['train']))\n",
        "plt.figure(figsize=(16, 24))\n",
        "grid_imgs = torchvision.utils.make_grid(samples[:24])\n",
        "plt.imshow(grid_imgs.permute(1, 2, 0).numpy()) # [B, W, H] -> [W, H, B]"
      ],
      "metadata": {
        "id": "feJr9MVy85bk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = torchvision.models.resnet101(weights='IMAGENET1K_V2')"
      ],
      "metadata": {
        "id": "QSvklOqa9H1j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "id": "pbCdbA8ECOiW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Sequential(\n",
        "    nn.Linear(num_ftrs, 1000),\n",
        "    nn.Linear(1000, 2)\n",
        ")"
      ],
      "metadata": {
        "id": "-Lfd6toQaRyB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.to(device)\n",
        "criterion = nn.CrossEntropyLoss().to(device)\n",
        "optimizer = torch.optim.Adam(\n",
        "    model.parameters(), lr=lr, amsgrad=True)\n",
        "scheduler = torch.optim.lr_scheduler.MultiStepLR(\n",
        "    optimizer, milestones=[500,1000,1500], gamma=0.5)"
      ],
      "metadata": {
        "id": "XqiQingL_2vT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_epoch(phase, dataloader):\n",
        "    if phase == 'train':\n",
        "        model.train()\n",
        "    else:\n",
        "        model.eval()\n",
        "\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0\n",
        "\n",
        "    y_test = []\n",
        "    y_pred = []\n",
        "\n",
        "    all_elems_count = 0\n",
        "    cur_tqdm = tqdm(dataloader)\n",
        "\n",
        "    for inputs, labels in cur_tqdm:\n",
        "\n",
        "        bz = inputs.shape[0]\n",
        "        all_elems_count += bz\n",
        "\n",
        "        inputs = inputs.to(device, non_blocking=True)\n",
        "        labels = labels.to(device, non_blocking=True)\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        if phase == 'train':\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        y_test.extend(labels.detach().cpu().numpy())\n",
        "        y_pred.extend(preds.detach().cpu().numpy())\n",
        "        running_loss += loss.item() * bz\n",
        "        corrects_cnt = torch.sum(preds == labels.detach())\n",
        "        running_corrects += corrects_cnt\n",
        "        show_dict = {'Loss': f'{loss.item():.6f}',\n",
        "                     'Corrects': f'{corrects_cnt.item()}/{bz}',\n",
        "                     'Accuracy': f'{(corrects_cnt * 100 / bz).item():.3f}%'}\n",
        "        cur_tqdm.set_postfix(show_dict)\n",
        "\n",
        "    conf_matrix = metrics.confusion_matrix(y_test, y_pred, labels=range(num_classes))\n",
        "\n",
        "    print(\"Calculating metrics...\")\n",
        "    f05_macro = metrics.fbeta_score(y_test, y_pred, average=\"macro\", beta=0.5)\n",
        "    f1_macro = metrics.f1_score(y_test, y_pred, average=\"macro\")\n",
        "    epoch_loss = running_loss / all_elems_count\n",
        "    epoch_acc = running_corrects.float().item() / all_elems_count\n",
        "\n",
        "    return epoch_loss, epoch_acc, f05_macro, f1_macro, conf_matrix\n",
        "\n",
        "def test_epoch(dataloader):\n",
        "    with torch.inference_mode(): # существенно ускоряет этап тестирования\n",
        "        return run_epoch('test', dataloader)\n",
        "\n",
        "def train_epoch(dataloader):\n",
        "    return run_epoch('train', dataloader)"
      ],
      "metadata": {
        "id": "y-p9nr6Oao1k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def vis(test_accs, confusion_mtxes, labels, figsize=(50, 80)):\n",
        "\n",
        "    cm = confusion_mtxes[np.argmax(test_accs)]\n",
        "\n",
        "    cm_sum = np.sum(cm, axis=0, keepdims=True)\n",
        "    cm_perc = cm / cm_sum * 100\n",
        "\n",
        "    annot = np.empty_like(cm).astype(str)\n",
        "    nrows, ncols = cm.shape\n",
        "\n",
        "    for i in range(nrows):\n",
        "        for j in range(ncols):\n",
        "            c = cm[i, j]\n",
        "            p = cm_perc[i, j]\n",
        "            if c == 0:\n",
        "                annot[i, j] = ''\n",
        "            else:\n",
        "                annot[i, j] = '%.1f%%' % p\n",
        "\n",
        "    cm = pd.DataFrame(cm, index=labels, columns=labels)\n",
        "\n",
        "    cm.index.name = 'Actual'\n",
        "    cm.columns.name = 'Predicted'\n",
        "\n",
        "    fig = plt.figure(figsize=figsize)\n",
        "\n",
        "    plt.subplot(2, 1, 1)\n",
        "    plt.plot(test_accs, 'g')\n",
        "    plt.grid(True)\n",
        "\n",
        "    plt.subplot(2, 1, 2)\n",
        "    sns.heatmap(cm, annot=annot, fmt='', cmap=\"Blues\", square=False)\n",
        "\n",
        "    fig.tight_layout()\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "7_Z0gHuNac_2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "log_folder = 'logs'\n",
        "os.makedirs(log_folder, exist_ok=True)\n",
        "\n",
        "def train_model(dataloaders, num_epochs=5):\n",
        "    print(f\"Training model with params:\")\n",
        "    print(f\"Optim: {optimizer}\")\n",
        "    print(f\"Criterion: {criterion}\")\n",
        "\n",
        "    phases = ['train', 'test']\n",
        "    for phase in dataloaders:\n",
        "        if phase not in phases:\n",
        "            phases.append(phase)\n",
        "\n",
        "    saved_epoch_losses = {phase: [] for phase in phases}\n",
        "    saved_epoch_accuracies = {phase: [] for phase in phases}\n",
        "    saved_epoch_f1_macros = {phase: [] for phase in phases}\n",
        "    saved_epoch_conf_matrices = {phase: [] for phase in phases}\n",
        "\n",
        "    for epoch in range(1, num_epochs + 1):\n",
        "        start_time = time.time()\n",
        "\n",
        "        print(\"=\" * 100)\n",
        "        print(f'Epoch {epoch}/{num_epochs}')\n",
        "        print('-' * 10)\n",
        "\n",
        "        for phase in phases:\n",
        "            print(\"--- Cur phase:\", phase)\n",
        "\n",
        "            epoch_loss, epoch_acc, f05_macro, f1_macro, conf_matrix = \\\n",
        "                train_epoch(dataloaders[phase]) if phase == 'train' \\\n",
        "                    else test_epoch(dataloaders[phase])\n",
        "\n",
        "            saved_epoch_losses[phase].append(epoch_loss)\n",
        "            saved_epoch_accuracies[phase].append(epoch_acc)\n",
        "            saved_epoch_f1_macros[phase].append(f1_macro)\n",
        "            saved_epoch_conf_matrices[phase].append(conf_matrix)\n",
        "\n",
        "            print(f'{phase} loss: {epoch_loss:.6f}, '\n",
        "                  f'acc: {epoch_acc:.6f}, '\n",
        "                  f'f05_macro: {f05_macro:.6f}, '\n",
        "                  f'f1_macro: {f1_macro:.6f}')\n",
        "\n",
        "            print(\"Confusion matrix:\")\n",
        "            print(conf_matrix)\n",
        "\n",
        "        model.eval()\n",
        "        if epoch > 1:\n",
        "            plt.title(f'Losses during training. Epoch {epoch}/{num_epochs}.')\n",
        "            plt.plot(range(1, epoch + 1), saved_epoch_losses['train'], label='Train Loss')\n",
        "            plt.plot(range(1, epoch + 1), saved_epoch_losses['test'], label='Test Loss')\n",
        "            plt.xlabel('Epochs')\n",
        "            plt.ylabel(criterion.__class__.__name__)\n",
        "            plt.legend(loc=\"upper left\")\n",
        "            plt.savefig(f'{log_folder}/loss_graph_epoch{epoch + 1}.png')\n",
        "            plt.show()\n",
        "            plt.close('all')\n",
        "\n",
        "            plt.title(f'Accuracies during training. Epoch {epoch}/{num_epochs}.')\n",
        "            plt.plot(range(1, epoch + 1), saved_epoch_accuracies['train'], label='Train Acc')\n",
        "            plt.plot(range(1, epoch + 1), saved_epoch_accuracies['test'], label='Test Acc')\n",
        "            plt.xlabel('Epochs')\n",
        "            plt.ylabel('Accuracy')\n",
        "            plt.legend(loc=\"upper left\")\n",
        "            plt.savefig(f'{log_folder}/acc_graph_epoch{epoch + 1}.png')\n",
        "            plt.show()\n",
        "            plt.close('all')\n",
        "\n",
        "        end_time = time.time()\n",
        "        epoch_time = end_time - start_time\n",
        "        print(\"-\" * 10)\n",
        "        print(f\"Epoch Time: {math.floor(epoch_time // 60)}:{math.floor(epoch_time % 60):02d}\")\n",
        "\n",
        "    print(\"*** Training Completed ***\")\n",
        "\n",
        "    return saved_epoch_losses, saved_epoch_accuracies, saved_epoch_f1_macros, saved_epoch_conf_matrices"
      ],
      "metadata": {
        "id": "mL_VkBsnbD38"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 5\n",
        "classe_labels = range(num_classes)\n",
        "\n",
        "losses, accuracies, f1_macros, conf_matrices = train_model(dataloaders, num_epochs)\n",
        "vis(accuracies['test'], conf_matrices['test'], classe_labels)"
      ],
      "metadata": {
        "id": "A2vT9rXObLLJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filename_pth = 'ckpt_densenet121_catdog.pth'\n",
        "torch.save(model.state_dict(), filename_pth)"
      ],
      "metadata": {
        "id": "BykghKOBDBFJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test submission"
      ],
      "metadata": {
        "id": "PpFfqIMORQRi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(batch):\n",
        "  return (torch.stack([im for im, _ in batch]), [label for _, label in batch])\n",
        "\n",
        "testset = ImageDataset('test1', 'test.csv', transform=test_transform)\n",
        "testloader = DataLoader(testset, batch_size=32, shuffle=False, num_workers=num_workers, collate_fn=collate_fn)"
      ],
      "metadata": {
        "id": "JX5UQU9yQ2lO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "\n",
        "fn_list = []\n",
        "pred_list = []\n",
        "\n",
        "for x, fn in tqdm(testloader, leave=False):\n",
        "    with torch.no_grad():\n",
        "        x = x.to(device)\n",
        "\n",
        "        output = model(x)\n",
        "\n",
        "        pred = torch.argmax(output, dim=1)\n",
        "\n",
        "        fn_list += [n[:-4] for n in fn]\n",
        "        pred_list += [p.item() for p in pred]\n",
        "\n",
        "submission = pd.DataFrame({\"id\": fn_list, \"label\": pred_list})\n",
        "submission.to_csv('preds_densenet121.csv', index=False)"
      ],
      "metadata": {
        "id": "cNskpd6SDEp-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "samples, _ = next(iter(testloader))\n",
        "samples = samples.to(device)\n",
        "\n",
        "fig = plt.figure(figsize=(24, 16))\n",
        "fig.tight_layout()\n",
        "\n",
        "output = model(samples[:24])\n",
        "pred = torch.argmax(output, dim=1)\n",
        "pred = [p.item() for p in pred]\n",
        "\n",
        "ad = {0:'cat', 1:'dog'}\n",
        "\n",
        "for num, sample in enumerate(samples[:24]):\n",
        "    plt.subplot(4, 6, num+1)\n",
        "    plt.title(ad[pred[num]])\n",
        "    plt.axis('off')\n",
        "    plt.imshow(sample.permute(1, 2, 0).cpu().numpy())"
      ],
      "metadata": {
        "id": "4THD9CtxDF4i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ymtz9bVaTPTp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}